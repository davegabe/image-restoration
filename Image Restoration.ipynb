{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0T1DB8mQEdi"
   },
   "source": [
    "# **Image Restoration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsFrpqXCQrzQ"
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8O0XW8vXQ1UI"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Environment variables\n",
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "QUANTITY = 100\n",
    "EPOCH_SAVE = 25\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# Test if it's running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:  # If it's running in Google Colab, mount the drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Environment variables\n",
    "    HOME = \"/content/drive/MyDrive/Image Restoration/image-restoration/\"\n",
    "    LOCALHOME = \"/content/image-restoration/\"\n",
    "    TRAINING_PATH = LOCALHOME + \"Dataset/Training/\"\n",
    "    EVALUATION_PATH = LOCALHOME + \"Dataset/Evaluation/\"\n",
    "    BATCH_SIZE = 160\n",
    "    RESULTS_PATH = HOME + \"Results/\" # Default HOME. Change this to LOCALHOME to test locally\n",
    "    MODEL_PATH = HOME + \"Model/\" # Default HOME. Change this to LOCALHOME to test locally\n",
    "\n",
    "    os.chdir(\"/content\")\n",
    "    if not os.path.exists(LOCALHOME): # If the repo isn't cloned yet, clone it\n",
    "        # Clone the repo\n",
    "        !git clone https://github.com/davegabe/image-restoration.git\n",
    "        # Copy the dataset\n",
    "        with zipfile.ZipFile(HOME + \"Dataset/dataset-ready-to-use.zip\", \"r\") as zip_ref:\n",
    "            zip_ref.extractall(LOCALHOME + \"Dataset/\")\n",
    "        os.chdir(LOCALHOME)\n",
    "    else: # If it's already cloned, update it\n",
    "        os.chdir(LOCALHOME)\n",
    "        !git pull\n",
    "else:  # If it's running in local machine, use the local path\n",
    "    # Environment variables\n",
    "    HOME = \"./\"\n",
    "    TRAINING_PATH = HOME + \"Dataset/Training/\"\n",
    "    EVALUATION_PATH = HOME + \"Dataset/Evaluation/\"\n",
    "    RESULTS_PATH = HOME + \"Results/\"\n",
    "    MODEL_PATH = HOME + \"Model/\"\n",
    "    os.chdir(HOME)\n",
    "\n",
    "os.makedirs(TRAINING_PATH + \"Original/\", exist_ok=True)\n",
    "os.makedirs(TRAINING_PATH + \"Corrupted/\", exist_ok=True)\n",
    "os.makedirs(EVALUATION_PATH + \"Original/\", exist_ok=True)\n",
    "os.makedirs(EVALUATION_PATH + \"Corrupted/\", exist_ok=True)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzycRi81QJyU"
   },
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqnWf5IaP9Hr"
   },
   "outputs": [],
   "source": [
    "from data.downloader import adjustAndCrop, splitData\n",
    "from data.corrupter import corrupt\n",
    "import shutil\n",
    "\n",
    "# Test if it's running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "def doYouReallyWantToDownload():\n",
    "    trainingFiles = len(os.listdir(TRAINING_PATH + \"Original/\")) + len(os.listdir(TRAINING_PATH + \"Original/\"))\n",
    "    evaluationFiles = len(os.listdir(EVALUATION_PATH + \"Original/\")) + len(os.listdir(EVALUATION_PATH + \"Corrupted/\"))\n",
    "    if trainingFiles + evaluationFiles > 0:\n",
    "        if input(\"Oops, there seems to be some files already, do you want to overwrite them? (y/n)\").capitalize() == \"Y\":\n",
    "            # remove all training files\n",
    "            shutil.rmtree(TRAINING_PATH + \"Original/\")\n",
    "            shutil.rmtree(TRAINING_PATH + \"Corrupted/\")\n",
    "            shutil.rmtree(EVALUATION_PATH + \"Original/\")\n",
    "            shutil.rmtree(EVALUATION_PATH + \"Corrupted/\")\n",
    "            os.makedirs(TRAINING_PATH + \"Original/\", exist_ok=True)\n",
    "            os.makedirs(TRAINING_PATH + \"Corrupted/\", exist_ok=True)\n",
    "            os.makedirs(EVALUATION_PATH + \"Original/\", exist_ok=True)\n",
    "            os.makedirs(EVALUATION_PATH + \"Corrupted/\", exist_ok=True)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "            return True\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Not implemented yet. Upload the \\\"dataset-ready-to-use.zip\\\" to the drive manually.\")\n",
    "else:\n",
    "    print(\"Generating dataset...\")\n",
    "\n",
    "    if doYouReallyWantToDownload():\n",
    "        # Unzip the dataset placed inside \"./Dataset/landscape-pictures-kaggle.zip\"\n",
    "        with zipfile.ZipFile(HOME + \"Dataset/landscape-pictures-kaggle.zip\", \"r\") as zip_ref:\n",
    "            zip_ref.extractall(TRAINING_PATH + \"Original\")\n",
    "\n",
    "        adjustAndCrop(TRAINING_PATH + \"Original/\", WIDTH, HEIGHT)\n",
    "        splitData(TRAINING_PATH + \"Original/\", EVALUATION_PATH + \"Original/\")\n",
    "        corrupt(TRAINING_PATH + \"Original/\", EVALUATION_PATH + \"Original/\", TRAINING_PATH + \"Corrupted/\", EVALUATION_PATH + \"Corrupted/\")\n",
    "        print(\"Dataset generated.\")\n",
    "    else:\n",
    "        print(\"Dataset not generated (already exists).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmlKnGlOQP3W"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDVuF7LlQeO2"
   },
   "outputs": [],
   "source": [
    "from autoencoder.train import train\n",
    "\n",
    "train(TRAINING_PATH, MODEL_PATH, EPOCH_SAVE, BATCH_SIZE, WIDTH, HEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOZ1-YhBQoVB"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wNuI6w_QkBP"
   },
   "outputs": [],
   "source": [
    "from autoencoder.test import test\n",
    "\n",
    "TRAINING_PATH = HOME + \"Dataset/Training/\"\n",
    "EVALUATION_PATH = HOME + \"Dataset/Evaluation/\"\n",
    "test(MODEL_PATH, EVALUATION_PATH, RESULTS_PATH, BATCH_SIZE, WIDTH, HEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove RESULTS_PATH and MODEL_PATH and its contents\n",
    "import shutil\n",
    "shutil.rmtree(RESULTS_PATH)\n",
    "shutil.rmtree(MODEL_PATH)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMdEXIhQUK3geB/cnDXf/Ic",
   "collapsed_sections": [
    "KsFrpqXCQrzQ",
    "bzycRi81QJyU",
    "XmlKnGlOQP3W",
    "EOZ1-YhBQoVB"
   ],
   "name": "Image Reconstruction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python ('image-restoration')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
