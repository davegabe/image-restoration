{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0T1DB8mQEdi"
   },
   "source": [
    "# **Image Restoration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsFrpqXCQrzQ"
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8O0XW8vXQ1UI"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "# Test if it's running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:  # If it's running in Google Colab, mount the drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    HOME = \"/content/drive/MyDrive/Image Restoration/image-restoration\"\n",
    "    if not os.path.exists(HOME): # If the repo isn't cloned yet, clone it\n",
    "        os.chdir(\"/content/drive/MyDrive/Image Restoration/\")\n",
    "        !git clone https://github.com/davegabe/image-restoration.git\n",
    "        os.chdir(HOME)\n",
    "    else: # If it's already cloned, update it\n",
    "        os.chdir(HOME)\n",
    "        !git pull\n",
    "else:  # If it's running in local machine, use the local path\n",
    "    HOME = \"./\"\n",
    "    os.chdir(HOME)\n",
    "\n",
    "TRAINING_PATH = HOME + \"Dataset/Training/\"\n",
    "EVALUATION_PATH = HOME + \"Dataset/Evaluation/\"\n",
    "RESULTS_PATH = HOME + \"Results/\"\n",
    "MODEL_PATH = HOME + \"Model/\"\n",
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "KEYWORD = \"landscape\"\n",
    "QUANTITY = 100\n",
    "EPOCH_SAVE = 25\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "os.makedirs(TRAINING_PATH + \"Original/\", exist_ok=True)\n",
    "os.makedirs(TRAINING_PATH + \"Corrupted/\", exist_ok=True)\n",
    "os.makedirs(EVALUATION_PATH + \"Original/\", exist_ok=True)\n",
    "os.makedirs(EVALUATION_PATH + \"Corrupted/\", exist_ok=True)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzycRi81QJyU"
   },
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqnWf5IaP9Hr"
   },
   "outputs": [],
   "source": [
    "from data.downloader import download, adjustAndCrop, splitData\n",
    "from data.corrupter import corrupt\n",
    "import shutil\n",
    "\n",
    "def doYouReallyWantToDownload():\n",
    "    trainingFiles = len(os.listdir(TRAINING_PATH + \"Original/\")) + len(os.listdir(TRAINING_PATH + \"Original/\"))\n",
    "    evaluationFiles = len(os.listdir(EVALUATION_PATH + \"Original/\")) + len(os.listdir(EVALUATION_PATH + \"Corrupted/\"))\n",
    "    if trainingFiles + evaluationFiles > 0:\n",
    "        if input(\"Oops, there seems to be some files already, do you want to overwrite them? (y/n)\").capitalize() == \"Y\":\n",
    "            # remove all training files\n",
    "            shutil.rmtree(TRAINING_PATH + \"Original/\")\n",
    "            shutil.rmtree(TRAINING_PATH + \"Corrupted/\")\n",
    "            shutil.rmtree(EVALUATION_PATH + \"Original/\")\n",
    "            shutil.rmtree(EVALUATION_PATH + \"Corrupted/\")\n",
    "            os.makedirs(TRAINING_PATH + \"Original/\", exist_ok=True)\n",
    "            os.makedirs(TRAINING_PATH + \"Corrupted/\", exist_ok=True)\n",
    "            os.makedirs(EVALUATION_PATH + \"Original/\", exist_ok=True)\n",
    "            os.makedirs(EVALUATION_PATH + \"Corrupted/\", exist_ok=True)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "            return True\n",
    "\n",
    "\n",
    "print(\"Generating dataset...\")\n",
    "\n",
    "\n",
    "\n",
    "if True:\n",
    "    # ALTERNATIVE:\n",
    "    # Dowload https://www.kaggle.com/datasets/arnaud58/landscape-pictures and put in TRAINING_PATH + \"Original/\"\n",
    "    adjustAndCrop(TRAINING_PATH + \"Original/\", WIDTH, HEIGHT)\n",
    "    splitData(TRAINING_PATH + \"Original/\", EVALUATION_PATH + \"Original/\")\n",
    "    corrupt(TRAINING_PATH + \"Original/\", EVALUATION_PATH + \"Original/\", TRAINING_PATH + \"Corrupted/\", EVALUATION_PATH + \"Corrupted/\")\n",
    "    print(\"Dataset generated.\")\n",
    "elif doYouReallyWantToDownload():\n",
    "    download(TRAINING_PATH + \"Original/\", EVALUATION_PATH + \"Original/\", WIDTH, HEIGHT, KEYWORD, QUANTITY)\n",
    "    corrupt(TRAINING_PATH + \"Original/\", EVALUATION_PATH + \"Original/\", TRAINING_PATH + \"Corrupted/\", EVALUATION_PATH + \"Corrupted/\")\n",
    "    print(\"Dataset generated.\")\n",
    "else:\n",
    "    print(\"Dataset not generated (already exists).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmlKnGlOQP3W"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iDVuF7LlQeO2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 38/38 [00:10<00:00,  3.68it/s]\n",
      "Epoch 2 | Loss 0.10894282907247543: 100%|██████████| 38/38 [00:09<00:00,  3.81it/s]\n",
      "Epoch 3 | Loss 0.11107807606458664: 100%|██████████| 38/38 [00:10<00:00,  3.80it/s]\n",
      "Epoch 4 | Loss 0.0861082449555397: 100%|██████████| 38/38 [00:09<00:00,  3.81it/s]\n",
      "Epoch 5 | Loss 0.06863630563020706: 100%|██████████| 38/38 [00:10<00:00,  3.79it/s]\n",
      "Epoch 6 | Loss 0.07144181430339813: 100%|██████████| 38/38 [00:10<00:00,  3.80it/s]\n",
      "Epoch 7 | Loss 0.05975870415568352: 100%|██████████| 38/38 [00:10<00:00,  3.79it/s]\n",
      "Epoch 8 | Loss 0.05519816279411316: 100%|██████████| 38/38 [00:10<00:00,  3.79it/s]\n",
      "Epoch 9 | Loss 0.05328061431646347: 100%|██████████| 38/38 [00:09<00:00,  3.80it/s]\n",
      "Epoch 10 | Loss 0.051912251859903336: 100%|██████████| 38/38 [00:09<00:00,  3.81it/s]\n",
      "Epoch 11 | Loss 0.05298558622598648: 100%|██████████| 38/38 [00:10<00:00,  3.80it/s]\n",
      "Epoch 12 | Loss 0.051912836730480194: 100%|██████████| 38/38 [00:09<00:00,  3.80it/s]\n",
      "Epoch 13 | Loss 0.052651986479759216: 100%|██████████| 38/38 [00:09<00:00,  3.83it/s]\n",
      "Epoch 14 | Loss 0.04770408198237419: 100%|██████████| 38/38 [00:09<00:00,  3.83it/s]\n",
      "Epoch 15 | Loss 0.04946024343371391: 100%|██████████| 38/38 [00:09<00:00,  3.80it/s]\n",
      "Epoch 16 | Loss 0.05157666280865669: 100%|██████████| 38/38 [00:09<00:00,  3.80it/s]\n",
      "Epoch 17 | Loss 0.04296945780515671: 100%|██████████| 38/38 [00:09<00:00,  3.82it/s]\n",
      "Epoch 18 | Loss 0.04660646617412567: 100%|██████████| 38/38 [00:10<00:00,  3.74it/s]\n",
      "Epoch 19 | Loss 0.05144551023840904: 100%|██████████| 38/38 [00:10<00:00,  3.76it/s]\n",
      "Epoch 20 | Loss 0.04453305900096893: 100%|██████████| 38/38 [00:10<00:00,  3.76it/s]\n",
      "Epoch 21 | Loss 0.04894978925585747: 100%|██████████| 38/38 [00:09<00:00,  3.81it/s]\n",
      "Epoch 22 | Loss 0.044947415590286255: 100%|██████████| 38/38 [00:10<00:00,  3.73it/s]\n",
      "Epoch 23 | Loss 0.039930425584316254: 100%|██████████| 38/38 [00:10<00:00,  3.63it/s]\n",
      "Epoch 24 | Loss 0.042829569429159164: 100%|██████████| 38/38 [00:10<00:00,  3.56it/s]\n",
      "Epoch 25 | Loss 0.042694054543972015: 100%|██████████| 38/38 [00:10<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED MODEL] Epoch: 25 | Saved to ./Model/model_25.pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Loss 0.04614834859967232: 100%|██████████| 38/38 [00:10<00:00,  3.65it/s]\n",
      "Epoch 27 | Loss 0.04672057181596756:  32%|███▏      | 12/38 [00:03<00:07,  3.64it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'output_images' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Riccardo\\Desktop\\image-restoration\\autoencoder\\train.py:68\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_data_loader, criterion, optimizer, epoch, epochs_save, model_path, device)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m i, (original_images, corrupted_images) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(train_data_loader, desc\u001b[39m=\u001b[39mdescription)):\n\u001b[0;32m     67\u001b[0m     \u001b[39m# send the images to the device\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     original_images: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m original_images\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     69\u001b[0m     corrupted_images: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m corrupted_images\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Riccardo\\Desktop\\image-restoration\\Image Restoration.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Riccardo/Desktop/image-restoration/Image%20Restoration.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mautoencoder\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m train\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Riccardo/Desktop/image-restoration/Image%20Restoration.ipynb#ch0000006?line=2'>3</a>\u001b[0m train(TRAINING_PATH, MODEL_PATH, EPOCH_SAVE, BATCH_SIZE, WIDTH, HEIGHT)\n",
      "File \u001b[1;32mc:\\Users\\Riccardo\\Desktop\\image-restoration\\autoencoder\\train.py:40\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(training_path, model_path, epochs_save, batch_size, width, height)\u001b[0m\n\u001b[0;32m     35\u001b[0m train_data_loader \u001b[39m=\u001b[39m DataLoader(train_data, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m \u001b[39m# summary(model, (3, 128, 128))\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m train_model(model, train_data_loader, criterion, optimizer,\n\u001b[0;32m     41\u001b[0m             epoch, epochs_save, model_path, device)\n",
      "File \u001b[1;32mc:\\Users\\Riccardo\\Desktop\\image-restoration\\autoencoder\\train.py:95\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_data_loader, criterion, optimizer, epoch, epochs_save, model_path, device)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdel\u001b[39;00m original_images\n\u001b[0;32m     94\u001b[0m \u001b[39mdel\u001b[39;00m corrupted_images\n\u001b[1;32m---> 95\u001b[0m \u001b[39mdel\u001b[39;00m output_images\n\u001b[0;32m     96\u001b[0m \u001b[39mdel\u001b[39;00m loss\n\u001b[0;32m     97\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache() \u001b[39m# clear the cache\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'output_images' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from autoencoder.train import train\n",
    "\n",
    "train(TRAINING_PATH, MODEL_PATH, EPOCH_SAVE, BATCH_SIZE, WIDTH, HEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOZ1-YhBQoVB"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5wNuI6w_QkBP"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AutoEncoder:\n\tMissing key(s) in state_dict: \"encoder.5.weight\", \"encoder.5.bias\", \"decoder.5.weight\", \"decoder.5.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.6.weight\", \"encoder.6.bias\", \"decoder.4.weight\", \"decoder.4.bias\", \"decoder.6.weight\", \"decoder.6.bias\". \n\tsize mismatch for decoder.3.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 64, 3, 3]).\n\tsize mismatch for decoder.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Riccardo\\Desktop\\image-restoration\\Image Restoration.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Riccardo/Desktop/image-restoration/Image%20Restoration.ipynb#ch0000008?line=2'>3</a>\u001b[0m TRAINING_PATH \u001b[39m=\u001b[39m HOME \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataset/Training/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Riccardo/Desktop/image-restoration/Image%20Restoration.ipynb#ch0000008?line=3'>4</a>\u001b[0m EVALUATION_PATH \u001b[39m=\u001b[39m HOME \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataset/Evaluation/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Riccardo/Desktop/image-restoration/Image%20Restoration.ipynb#ch0000008?line=4'>5</a>\u001b[0m test(MODEL_PATH, EVALUATION_PATH, RESULTS_PATH, BATCH_SIZE, WIDTH, HEIGHT)\n",
      "File \u001b[1;32mc:\\Users\\Riccardo\\Desktop\\image-restoration\\autoencoder\\test.py:25\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(model_path, evaluation_path, results_path, batch_size, width, height)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mUse the trained model to restore the image.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m    results_path: The path to save the restored images.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m autoencoder, epoch \u001b[39m=\u001b[39m load_model(device, model_path, width, height)\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     27\u001b[0m     sys\u001b[39m.\u001b[39mexit(\u001b[39m\"\u001b[39m\u001b[39mModel missing\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Riccardo\\Desktop\\image-restoration\\autoencoder\\model.py:153\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(device, model_path, width, height)\u001b[0m\n\u001b[0;32m    150\u001b[0m     models\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(\n\u001b[0;32m    151\u001b[0m         x\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]))  \u001b[39m# Sort by epoch\u001b[39;00m\n\u001b[0;32m    152\u001b[0m     last_model \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, models[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])  \u001b[39m# Get the last model\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(last_model))  \u001b[39m# Load the last model\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     epoch \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(last_model\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\n\u001b[0;32m    155\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# Get the epoch\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39mreturn\u001b[39;00m model, epoch\n",
      "File \u001b[1;32mc:\\Users\\Riccardo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1492\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   1493\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1494\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1498\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1499\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AutoEncoder:\n\tMissing key(s) in state_dict: \"encoder.5.weight\", \"encoder.5.bias\", \"decoder.5.weight\", \"decoder.5.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.6.weight\", \"encoder.6.bias\", \"decoder.4.weight\", \"decoder.4.bias\", \"decoder.6.weight\", \"decoder.6.bias\". \n\tsize mismatch for decoder.3.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 64, 3, 3]).\n\tsize mismatch for decoder.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32])."
     ]
    }
   ],
   "source": [
    "from autoencoder.test import test\n",
    "\n",
    "TRAINING_PATH = HOME + \"Dataset/Training/\"\n",
    "EVALUATION_PATH = HOME + \"Dataset/Evaluation/\"\n",
    "test(MODEL_PATH, EVALUATION_PATH, RESULTS_PATH, BATCH_SIZE, WIDTH, HEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove RESULTS_PATH and MODEL_PATH and its contents\n",
    "import shutil\n",
    "shutil.rmtree(RESULTS_PATH)\n",
    "shutil.rmtree(MODEL_PATH)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMdEXIhQUK3geB/cnDXf/Ic",
   "collapsed_sections": [
    "KsFrpqXCQrzQ",
    "bzycRi81QJyU",
    "XmlKnGlOQP3W",
    "EOZ1-YhBQoVB"
   ],
   "name": "Image Reconstruction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "480592bc24ebcb8064038ed82e3891fcde3d179f44f2ff4596b0bf44eeb606b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
